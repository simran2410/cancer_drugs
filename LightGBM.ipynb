import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, RandomizedSearchCV
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, accuracy_score, precision_score, f1_score, recall_score
from sklearn.preprocessing import StandardScaler
import lightgbm as lgb
from math import sqrt
import time
import gc

np.random.seed(42)

def load_data():
    
    df = pd.read_csv('data.csv')  
   
    feature_names = ['feature1', 'feature2', 'feature3'] 
    X_df = df[feature_names]
    
   
    y_series = df['target']  
    
    return X_df, y_series



def train_and_evaluate_model(X_train, X_test, y_train, y_test):
    
    param_grid = {
        'n_estimators': [50, 100],
        'max_depth': [3, 5],
        'num_leaves': [15, 31],
        'learning_rate': [0.1, 0.2],
        'min_child_samples': [20],
        'subsample': [0.8],
        'colsample_bytree': [0.8],
        'reg_alpha': [0],
        'reg_lambda': [0]
    }
    
    lgb_params = {
        'random_state': 42,
        'verbose': -1,
        'n_jobs': -1
    }
    
    random_search = RandomizedSearchCV(
        estimator=lgb.LGBMRegressor(**lgb_params),
        param_distributions=param_grid,
        n_iter=6,
        cv=5,
        scoring='neg_root_mean_squared_error',
        n_jobs=-1,
        verbose=0,
        random_state=42,
        return_train_score=True
    )
    
    print("Training LightGBM model...")
    start_time = time.time()
    random_search.fit(X_train, y_train)
    
    
    best_params = random_search.best_params_
    
    
    focused_grid = {}
    for param, value in best_params.items():
        if param == 'n_estimators':
            focused_grid[param] = [value, min(300, value + 50)]
        elif param == 'learning_rate':
            focused_grid[param] = [value]
        else:
            focused_grid[param] = [value]
    
    
    grid_search = GridSearchCV(
        estimator=lgb.LGBMRegressor(**lgb_params),
        param_grid=focused_grid,
        cv=5,
        scoring='neg_root_mean_squared_error',
        n_jobs=-1,
        verbose=0
    )
    
    grid_search.fit(X_train, y_train)
    print(f"Model training completed in {time.time() - start_time:.2f} seconds")
    
    
    best_model = grid_search.best_estimator_
    
    
    y_pred = best_model.predict(X_test)
    y_train_pred = best_model.predict(X_train)
    
    
    rmse = sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    
    train_rmse = sqrt(mean_squared_error(y_train, y_train_pred))
    train_r2 = r2_score(y_train, y_train_pred)
    train_mae = mean_absolute_error(y_train, y_train_pred)
    
    
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores_rmse = -cross_val_score(best_model, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kf)
    cv_scores_r2 = cross_val_score(best_model, X_train, y_train, scoring='r2', cv=kf)
    cv_scores_mae = -cross_val_score(best_model, X_train, y_train, scoring='neg_mean_absolute_error', cv=kf)
    
    return {
        'model': best_model,
        'y_pred': y_pred,
        'y_train_pred': y_train_pred,
        'best_params': grid_search.best_params_,
        'metrics': {
            'rmse': rmse,
            'r2': r2,
            'mae': mae,
            'train_rmse': train_rmse,
            'train_r2': train_r2,
            'train_mae': train_mae,
            'cv_rmse': cv_scores_rmse,
            'cv_r2': cv_scores_r2,
            'cv_mae': cv_scores_mae
        }
    }

def main():
   
    try:
        X, y = load_data()
    except Exception as e:
        print(f"Error loading data: {e}")
        print("Please modify the load_data() function to match your dataset structure.")
        return
    
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    
    X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)
    X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)
    
    
    print("\n======= Training LightGBM Model =======")
    model_results = train_and_evaluate_model(X_train_scaled_df, X_test_scaled_df, y_train, y_test)
    
    
    best_model = model_results['model']
    y_pred = model_results['y_pred']
    y_train_pred = model_results['y_train_pred']
    
    
    errors = y_test - y_pred
    
    
    def binarize_outputs(actual, predicted, threshold=None):
        if threshold is None:
            threshold = np.median(actual)
        actual_binary = (actual > threshold).astype(int)
        predicted_binary = (predicted > threshold).astype(int)
        return actual_binary, predicted_binary, threshold
    
    y_train_binary, y_train_pred_binary, train_threshold = binarize_outputs(y_train, y_train_pred)
    y_test_binary, y_test_pred_binary, test_threshold = binarize_outputs(y_test, y_pred)
    
    
    train_accuracy = accuracy_score(y_train_binary, y_train_pred_binary)
    train_precision = precision_score(y_train_binary, y_train_pred_binary, zero_division=0)
    train_recall = recall_score(y_train_binary, y_train_pred_binary, zero_division=0)
    train_f1 = f1_score(y_train_binary, y_train_pred_binary, zero_division=0)
    
    test_accuracy = accuracy_score(y_test_binary, y_test_pred_binary)
    test_precision = precision_score(y_test_binary, y_test_pred_binary, zero_division=0)
    test_recall = recall_score(y_test_binary, y_test_pred_binary, zero_division=0)
    test_f1 = f1_score(y_test_binary, y_test_pred_binary, zero_division=0)
    
    print(f"\n{'='*60}")
    print(f"MODEL EVALUATION RESULTS")
    print(f"{'='*60}")
    
    print("\n== Regression Metrics ==")
    print(f"Training RMSE: {model_results['metrics']['train_rmse']:.4f}")
    print(f"Testing RMSE: {model_results['metrics']['rmse']:.4f}")
    print(f"Training R²: {model_results['metrics']['train_r2']:.4f}")
    print(f"Testing R²: {model_results['metrics']['r2']:.4f}")
    print(f"Training MAE: {model_results['metrics']['train_mae']:.4f}")
    print(f"Testing MAE: {model_results['metrics']['mae']:.4f}")
    
    print("\n== Classification Metrics (Binarized) ==")
    print(f"Binarization threshold: {test_threshold:.4f}")
    print(f"Training Accuracy: {train_accuracy:.4f}")
    print(f"Testing Accuracy: {test_accuracy:.4f}")
    print(f"Training Precision: {train_precision:.4f}")
    print(f"Testing Precision: {test_precision:.4f}")
    print(f"Training Recall: {train_recall:.4f}")
    print(f"Testing Recall: {test_recall:.4f}")
    print(f"Training F1 Score: {train_f1:.4f}")
    print(f"Testing F1 Score: {test_f1:.4f}")
    
    print("\n== 5-Fold Cross-Validation Results ==")
    print(f"CV RMSE: {model_results['metrics']['cv_rmse'].mean():.4f} (±{model_results['metrics']['cv_rmse'].std():.4f})")
    print(f"CV R²: {model_results['metrics']['cv_r2'].mean():.4f} (±{model_results['metrics']['cv_r2'].std():.4f})")
    print(f"CV MAE: {model_results['metrics']['cv_mae'].mean():.4f} (±{model_results['metrics']['cv_mae'].std():.4f})")
    
    print(f"\n== Best LightGBM Parameters ==")
    print(model_results['best_params'])
    
    
    print("\nGenerating plots...")
    
    try:
        
        plt.figure(figsize=(8, 6))
        plt.scatter(y_test, y_pred, alpha=0.6, color='red', s=50, edgecolor='black', linewidth=0.3)
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
                color='black', linestyle='-', linewidth=2)
        plt.title("Actual vs Predicted Values", fontsize=14)
        plt.xlabel("Actual", fontsize=12)
        plt.ylabel("Predicted", fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()
        
        
        plt.figure(figsize=(8, 6))
        plt.scatter(y_pred, errors, alpha=0.6, color='blue', s=50, edgecolor='black', linewidth=0.3)
        plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
        plt.title("Residual Plot", fontsize=14)
        plt.xlabel("Predicted", fontsize=12)
        plt.ylabel("Residuals", fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()
        
    except Exception as e:
        print(f"Error in plotting: {e}")
    
    
    gc.collect()
    print("\n" + "="*50)
    print("Model training and evaluation completed successfully!")
    print("="*50)

if __name__ == "__main__":
    main()